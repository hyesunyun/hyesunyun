---
layout: page
title: Medical Safety of LLMs
description: investigating the utility and harms of large language models for medical systematic reviews
importance: 1
category: research
---

The recent development of large language models (LLMs) have suggested the tantalizing possibility of automating several clinical tasks. Despite their strengths, LLMs are notorious for sometimes generating inaccurate (and potentially misleading) texts by hallucinating or omitting important information. In the context of outputs which might inform healthcare decisions, this may render LLMs unusable at best and dangerous at worst. I am interested in exploring issues and solutions of medical safety of LLMs.

Publications from this project:
- ["Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews"](https://arxiv.org/abs/2305.11828)