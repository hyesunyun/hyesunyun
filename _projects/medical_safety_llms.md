layout: page
title: medical safety of LLMs
description: investigating the issue of medical safety of LLMs
importance: 1
category: research

The recent development of large language models (LLMs) have suggested the tantalizing possibility of automating several clinical tasks. Despite their strengths, LLMs are notorious for sometimes generating inaccurate (and potentially misleading) texts by hallucinating or omitting important information. In the context of outputs which might inform healthcare decisions, this may render LLMs unusable at best and dangerous at worst. I am interested in exploring issues and solutions of medical safety of LLMs.